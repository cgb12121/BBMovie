spring.application.name=ai-assistant-service

server.port=8888
spring.security.oauth2.resourceserver.jwt.jwk-set-uri=http://localhost:8080/.well-known/jwks.json
#--- For Running in Docker ---
#spring.security.oauth2.resourceserver.jwt.jwk-set-uri=http://auth-service/.well-known/jwks.json

spring.r2dbc.url=r2dbc:mysql://${DB_HOST}:${DB_PORT}/${DB_NAME}
spring.r2dbc.username=${DB_USERNAME}
spring.r2dbc.password=${DB_ROOT_PASSWORD}

#### Not in used ###
logging.chat.enabled=true
# --- Spring Langchain4j Ollama StreamingChatModel Configuration (for streaming)
langchain4j.ollama.streaming-chat-model.base-url=${OLLAMA_URL}
langchain4j.ollama.streaming-chat-model.model-name=qwen3:0.6b-q4_K_M
langchain4j.ollama.streaming-chat-model.num-predict=2048
langchain4j.ollama.streaming-chat-model.think=false
langchain4j.ollama.streaming-chat-model.temperature=1.0
langchain4j.ollama.streaming-chat-model.top-p=0.9
langchain4j.ollama.streaming-chat-model.top-k=40
langchain4j.ollama.streaming-chat-model.repeat-penalty=1.2
langchain4j.ollama.streaming-chat-model.repeat-last-n=64
langchain4j.ollama.streaming-chat-model.timeout=30s
langchain4j.ollama.streaming-chat-model.max-retries=3
langchain4j.ollama.streaming-chat-model.log-requests=true
langchain4j.ollama.streaming-chat-model.log-responses=true
#### Not in used ###
# --- Spring Langchain4j Ollama ChatModel Configuration (for non-streaming) ---
langchain4j.ollama.chat-model.base-url=${OLLAMA_URL}
langchain4j.ollama.chat-model.model-name=qwen3:0.6b-q4_K_M
langchain4j.ollama.chat-model.num-predict=2048
langchain4j.ollama.chat-model.think=false
langchain4j.ollama.chat-model.temperature=0.7
langchain4j.ollama.chat-model.top-p=0.9
langchain4j.ollama.chat-model.top-k=40
langchain4j.ollama.chat-model.repeat-penalty=1.2
langchain4j.ollama.chat-model.repeat-last-n=64
langchain4j.ollama.chat-model.max-retries=3
langchain4j.ollama.chat-model.log-requests=true
langchain4j.ollama.chat-model.log-responses=true

#logging.level.dev.langchain4j=INFO
#logging.level.org.springframework.security=DEBUG
#logging.level.org.springframework.security.oauth2=DEBUG
#logging.level.io.r2dbc.spi=DEBUG
#logging.level.org.springframework.r2dbc.core=DEBUG
#logging.level.org.springframework.data.r2dbc=DEBUG

####### AI Low-level Configuration ######
ai.mode=${AI_MODE}
ai.active-model=${AI_MODEL}
ai.enable-persona=true
ai.logging.mode=INFO

# Database Configuration
ai.ollama.url=${OLLAMA_URL}
ai.temperature=0.7
ai.topK=40
ai.topP=0.9
ai.minP=0.05
ai.numCtx=32768
ai.numPredict=1024
ai.seed=2004

ai.datasource.username=${DB_USERNAME}
ai.datasource.password=${DB_PASSWORD}
ai.datasource.driver=${DB_DRIVER}
ai.datasource.host=${DB_HOST}
ai.datasource.port=${DB_PORT}
ai.datasource.database=${DB_NAME}
ai.datasource.load-samples=false

#Embedded Model Configuration
ai.embedding.model-name=${EMBEDDING_MODEL}
ai.embedding.index=${ELASTICSEARCH_MOVIES_INDEX}
ai.embedding.index.movies=${ELASTICSEARCH_MOVIES_INDEX}
ai.embedding.index.rag=${ELASTICSEARCH_CHAT_HISTORY_INDEX}
ai.embedding.dimension=${EMBEDDING_DIMENSION}
ai.embedding.embedding-field=${EMBEDDING_FIELD}

#Redis Configuration
ai.redis.host=${REDIS_HOST}
ai.redis.port=${REDIS_PORT}
ai.redis.password=${REDIS_PASSWORD}
ai.redis.database=${REDIS_DATABASE}

#Elasticsearch Configuration
ai.rag.elasticsearch.host=${ELASTICSEARCH_HOST}
ai.rag.elasticsearch.port=${ELASTICSEARCH_PORT}
ai.rag.elasticsearch.scheme=${ELASTICSEARCH_SCHEME}
